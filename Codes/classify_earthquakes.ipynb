{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import sys, os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "random_state = 6\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_path = '../../pipeline_modules/'\n",
    "sys.path.append(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23460, 73)\n",
      "Index(['id', 'mfccs_0', 'mfccs_1', 'mfccs_2', 'mfccs_3', 'mfccs_4', 'mfccs_5',\n",
      "       'mfccs_6', 'mfccs_7', 'mfccs_8', 'mfccs_9', 'mfccs_10', 'mfccs_11',\n",
      "       'mfccs_12', 'mfccs_13', 'mfccs_14', 'mfccs_15', 'mfccs_16', 'mfccs_17',\n",
      "       'mfccs_18', 'mfccs_19', 'mfccs_20', 'mfccs_21', 'mfccs_22', 'mfccs_23',\n",
      "       'mfccs_24', 'mfccs_25', 'mfccs_26', 'mfccs_27', 'mfccs_28', 'mfccs_29',\n",
      "       'mfccs_30', 'mfccs_31', 'mfccs_32', 'mfccs_33', 'mfccs_34', 'mfccs_35',\n",
      "       'mfccs_36', 'mfccs_37', 'mfccs_38', 'mfccs_39', 'chroma_0', 'chroma_1',\n",
      "       'chroma_2', 'chroma_3', 'chroma_4', 'chroma_5', 'chroma_6', 'chroma_7',\n",
      "       'chroma_8', 'chroma_9', 'chroma_10', 'chroma_11', 'mel_max', 'mel_mean',\n",
      "       'power_max', 'power_mean', 'centiroid_mean', 'centiroid_max',\n",
      "       'centiroid_min', 'max_amplitude', 'mean_amplitude', 'max_psd',\n",
      "       'welch_max_psd', 'rmse_max', 'rmse_mean', 'moment', 'variation', 'skew',\n",
      "       'var', 'autocr', 'kurto', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# data62 = 'seismogram_data_62_new.csv'\n",
    "# data66 = 'seismogram_data_66_new.csv'\n",
    "data73 = 'seismogram_data_73_new.csv'\n",
    "df = pd.read_csv(data73)\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mfccs_0</th>\n",
       "      <th>mfccs_1</th>\n",
       "      <th>mfccs_2</th>\n",
       "      <th>mfccs_3</th>\n",
       "      <th>mfccs_4</th>\n",
       "      <th>mfccs_5</th>\n",
       "      <th>mfccs_6</th>\n",
       "      <th>mfccs_7</th>\n",
       "      <th>mfccs_8</th>\n",
       "      <th>...</th>\n",
       "      <th>welch_max_psd</th>\n",
       "      <th>rmse_max</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>moment</th>\n",
       "      <th>variation</th>\n",
       "      <th>skew</th>\n",
       "      <th>var</th>\n",
       "      <th>autocr</th>\n",
       "      <th>kurto</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE.113A.BHE.M.2013.43.3932</td>\n",
       "      <td>584.034711</td>\n",
       "      <td>67.395719</td>\n",
       "      <td>-1.123569</td>\n",
       "      <td>58.009457</td>\n",
       "      <td>12.714985</td>\n",
       "      <td>26.253530</td>\n",
       "      <td>8.813295</td>\n",
       "      <td>18.570522</td>\n",
       "      <td>28.410674</td>\n",
       "      <td>...</td>\n",
       "      <td>318.812225</td>\n",
       "      <td>8392.133789</td>\n",
       "      <td>4817.334473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.797894e+06</td>\n",
       "      <td>-0.046666</td>\n",
       "      <td>33360.179688</td>\n",
       "      <td>1.681353e+09</td>\n",
       "      <td>-0.228266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE.113A.BHN.M.2013.43.3932</td>\n",
       "      <td>585.279273</td>\n",
       "      <td>66.633911</td>\n",
       "      <td>-3.695100</td>\n",
       "      <td>57.115558</td>\n",
       "      <td>9.621800</td>\n",
       "      <td>28.749848</td>\n",
       "      <td>8.592028</td>\n",
       "      <td>16.574689</td>\n",
       "      <td>26.178886</td>\n",
       "      <td>...</td>\n",
       "      <td>247.526642</td>\n",
       "      <td>16092.809570</td>\n",
       "      <td>4819.573242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.954760e+06</td>\n",
       "      <td>0.476347</td>\n",
       "      <td>31333.093750</td>\n",
       "      <td>1.579188e+09</td>\n",
       "      <td>1.167933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE.113A.BHZ.M.2013.43.3932</td>\n",
       "      <td>582.517055</td>\n",
       "      <td>71.889762</td>\n",
       "      <td>4.812049</td>\n",
       "      <td>57.351785</td>\n",
       "      <td>15.596365</td>\n",
       "      <td>30.629524</td>\n",
       "      <td>11.819666</td>\n",
       "      <td>17.128889</td>\n",
       "      <td>27.543973</td>\n",
       "      <td>...</td>\n",
       "      <td>291.354401</td>\n",
       "      <td>25051.058594</td>\n",
       "      <td>9787.401367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.325927e+06</td>\n",
       "      <td>-0.225913</td>\n",
       "      <td>114514.218750</td>\n",
       "      <td>5.771631e+09</td>\n",
       "      <td>0.067572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE.319A.BHE.M.2013.43.3949</td>\n",
       "      <td>671.683429</td>\n",
       "      <td>68.050797</td>\n",
       "      <td>-31.188585</td>\n",
       "      <td>93.386678</td>\n",
       "      <td>11.076502</td>\n",
       "      <td>12.129126</td>\n",
       "      <td>3.464947</td>\n",
       "      <td>28.128156</td>\n",
       "      <td>15.251771</td>\n",
       "      <td>...</td>\n",
       "      <td>248.422974</td>\n",
       "      <td>8914.021484</td>\n",
       "      <td>4352.299805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.994568e+05</td>\n",
       "      <td>0.010802</td>\n",
       "      <td>24525.289062</td>\n",
       "      <td>1.236099e+09</td>\n",
       "      <td>0.360999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE.319A.BHN.M.2013.43.3949</td>\n",
       "      <td>688.401936</td>\n",
       "      <td>72.066389</td>\n",
       "      <td>-48.951186</td>\n",
       "      <td>98.619771</td>\n",
       "      <td>19.531902</td>\n",
       "      <td>9.367895</td>\n",
       "      <td>-3.468288</td>\n",
       "      <td>21.042504</td>\n",
       "      <td>17.588548</td>\n",
       "      <td>...</td>\n",
       "      <td>256.486481</td>\n",
       "      <td>7046.786621</td>\n",
       "      <td>4361.418457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.604528e+05</td>\n",
       "      <td>-0.216832</td>\n",
       "      <td>23690.130859</td>\n",
       "      <td>1.194006e+09</td>\n",
       "      <td>-0.145266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id     mfccs_0    mfccs_1    mfccs_2    mfccs_3  \\\n",
       "0  AE.113A.BHE.M.2013.43.3932  584.034711  67.395719  -1.123569  58.009457   \n",
       "1  AE.113A.BHN.M.2013.43.3932  585.279273  66.633911  -3.695100  57.115558   \n",
       "2  AE.113A.BHZ.M.2013.43.3932  582.517055  71.889762   4.812049  57.351785   \n",
       "3  AE.319A.BHE.M.2013.43.3949  671.683429  68.050797 -31.188585  93.386678   \n",
       "4  AE.319A.BHN.M.2013.43.3949  688.401936  72.066389 -48.951186  98.619771   \n",
       "\n",
       "     mfccs_4    mfccs_5    mfccs_6    mfccs_7    mfccs_8   ...    \\\n",
       "0  12.714985  26.253530   8.813295  18.570522  28.410674   ...     \n",
       "1   9.621800  28.749848   8.592028  16.574689  26.178886   ...     \n",
       "2  15.596365  30.629524  11.819666  17.128889  27.543973   ...     \n",
       "3  11.076502  12.129126   3.464947  28.128156  15.251771   ...     \n",
       "4  19.531902   9.367895  -3.468288  21.042504  17.588548   ...     \n",
       "\n",
       "   welch_max_psd      rmse_max    rmse_mean  moment     variation      skew  \\\n",
       "0     318.812225   8392.133789  4817.334473     0.0 -3.797894e+06 -0.046666   \n",
       "1     247.526642  16092.809570  4819.573242     0.0  3.954760e+06  0.476347   \n",
       "2     291.354401  25051.058594  9787.401367     0.0 -7.325927e+06 -0.225913   \n",
       "3     248.422974   8914.021484  4352.299805     0.0  7.994568e+05  0.010802   \n",
       "4     256.486481   7046.786621  4361.418457     0.0  8.604528e+05 -0.216832   \n",
       "\n",
       "             var        autocr     kurto  target  \n",
       "0   33360.179688  1.681353e+09 -0.228266       1  \n",
       "1   31333.093750  1.579188e+09  1.167933       1  \n",
       "2  114514.218750  5.771631e+09  0.067572       1  \n",
       "3   24525.289062  1.236099e+09  0.360999       1  \n",
       "4   23690.130859  1.194006e+09 -0.145266       1  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = shuffle(df, random_state = random_state)\n",
    "df_train, df_test = train_test_split(df, test_size = 0.20, random_state= random_state)\n",
    "mms = StandardScaler()\n",
    "X_train = mms.fit_transform(df_train.drop(['id', 'target', 'moment', 'variation'], axis=1))\n",
    "Y_train = df_train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector machine\n",
    "\n",
    "In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as Platt scaling exist to use SVM in a probabilistic classification setting). An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best parameter using GridSearchCV\n",
    "\n",
    "Exhaustive search over specified parameter values for an estimator. GridSearchCV implements a “fit” and a “score” method. It also implements “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used. The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state = random_state)\n",
    "svm_clss = svm.SVC(class_weight = 'balanced', random_state = random_state) \n",
    "\n",
    "param_dist = {'C': np.linspace(0.1, 10, 20), \n",
    "              'gamma': np.linspace(0.1, 0.00008, 30)}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "\n",
    "grid_clf = RandomizedSearchCV(estimator = svm_clss, param_distributions = param_dist, n_iter = 20, cv = cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=6, shuffle=True),\n",
       "          error_score='raise',\n",
       "          estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=6, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          fit_params={}, iid=True, n_iter=20, n_jobs=-1,\n",
       "          param_distributions={'C': array([  0.1    ,   0.62105,   1.14211,   1.66316,   2.18421,   2.70526,\n",
       "         3.22632,   3.74737,   4.26842,   4.78947,   5.31053,   5.83158,\n",
       "         6.35263,   6.87368,   7.39474,   7.91579,   8.43684,   8.95789,\n",
       "         9.47895,  10.     ]), 'gamma': array([  1.0000...    1.73076e-02,   1.38621e-02,   1.04166e-02,   6.97103e-03,\n",
       "         3.52552e-03,   8.00000e-05])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.068990344827586203, 'C': 5.8315789473684214}\n",
      "0.86210571185\n",
      "SVC(C=5.8315789473684214, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.068990344827586203,\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=6,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_clf.best_params_)\n",
    "print(grid_clf.best_score_)\n",
    "print(grid_clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use best parameters to make final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=4, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.08, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=6, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_model = svm.SVC(C=4, cache_size=200, coef0=0.0, class_weight='balanced',\n",
    "  decision_function_shape=None, degree=3, gamma=0.08, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state = random_state, shrinking=True,\n",
    "  tol=0.001, verbose=True)\n",
    "\n",
    "svm_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The accuracy of the model is 0.8751065643648764\n",
      "\n",
      "2. Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.90      0.89      2594\n",
      "          1       0.87      0.84      0.86      2098\n",
      "\n",
      "avg / total       0.88      0.88      0.87      4692\n",
      " \n",
      "\n",
      "3. Confusion matrix \n",
      " [[2337  329]\n",
      " [ 257 1769]] \n",
      "\n",
      "4. Roc_Auc score \n",
      " 0.8748716053643223\n"
     ]
    }
   ],
   "source": [
    "X_test  = mms.fit_transform(df_test.drop(['id', 'target', 'moment', 'variation'], axis=1))\n",
    "Y_test = df_test['target']\n",
    "\n",
    "Y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print('1. The accuracy of the model is {}\\n'.format(accuracy_score(Y_test, Y_pred)))\n",
    "print('2. Classification report \\n {} \\n'.format(classification_report(Y_test, Y_pred)))\n",
    "print('3. Confusion matrix \\n {} \\n'.format(confusion_matrix(Y_pred, Y_test)))\n",
    "print('4. Roc_Auc score \\n {}'.format(roc_auc_score(Y_pred, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classified_df = pd.DataFrame([], columns=['stations', 'original', 'predicted'])\n",
    "misclassified_df = pd.DataFrame([], columns=['stations', 'original', 'predicted'])\n",
    "\n",
    "for i, label in enumerate(Y_test):\n",
    "    result = svm_model.predict(X_test[i, :])\n",
    "    \n",
    "    if result[0] == label:    \n",
    "        classified_df.loc[i] = [df_test.iloc[i, 0], label, result[0]]\n",
    "    else:\n",
    "        misclassified_df.loc[i] = [df_test.iloc[i, 0], label, result[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       stations original predicted\n",
      "1   US.BOZ.BHE.M.2004.361.11326        0         0\n",
      "2  NM.BLO.BHZ.M.1998.131.102716        1         1\n",
      "3   DR.SDD.BHE.M.2010.71.234131        0         0\n",
      "4   AV.MGOD.BHE.M.2017.246.3375        1         1\n",
      "5  TA.W18A.BHZ.M.2017.246.34145        1         1\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "                        stations original predicted\n",
      "0   UW.HEBO.BHE.M.2017.246.34025        1         0\n",
      "49  US.DGMT.BHZ.M.2017.297.11114        0         1\n",
      "51  N4.V48A.BHN.M.2017.297.11232        0         1\n",
      "61    CU.TGUH.BH1.M.2016.6.14355        1         0\n",
      "76  XZ.KIAG.BHE.M.2010.71.233115        0         1\n"
     ]
    }
   ],
   "source": [
    "print(classified_df.head())\n",
    "print('\\n----------------------------------------------------------------------\\n')\n",
    "print(misclassified_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = {'miss': misclassified_df, 'good':classified_df }\n",
    "output = open('classification_data.pkl', 'wb')\n",
    "pickle.dump(data, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### robustness of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_robust = 'seismogram_data_73_new_robust.csv'\n",
    "df_robust = pd.read_csv(data73)\n",
    "df_robust = shuffle(df_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The accuracy of the model is 0.9685421994884911\n",
      "\n",
      "2. Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97     12962\n",
      "          1       0.96      0.96      0.96     10498\n",
      "\n",
      "avg / total       0.97      0.97      0.97     23460\n",
      " \n",
      "\n",
      "3. Confusion matrix \n",
      " [[12594   370]\n",
      " [  368 10128]] \n",
      "\n",
      "4. Roc_Auc score \n",
      " 0.9681992252466491\n"
     ]
    }
   ],
   "source": [
    "df_robust_test = df_robust.drop(['id', 'target', 'moment', 'variation'], axis=1)\n",
    "df_robust_target = df_robust['target']\n",
    "\n",
    "X_test  = mms.fit_transform(df_robust_test)\n",
    "Y_test = df_robust_target\n",
    "\n",
    "Y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print('1. The accuracy of the model is {}\\n'.format(accuracy_score(Y_test, Y_pred)))\n",
    "print('2. Classification report \\n {} \\n'.format(classification_report(Y_test, Y_pred)))\n",
    "print('3. Confusion matrix \\n {} \\n'.format(confusion_matrix(Y_pred, Y_test)))\n",
    "print('4. Roc_Auc score \\n {}'.format(roc_auc_score(Y_pred, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinement history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"border: 1px solid black;\">\n",
    "  <tr>\n",
    "    <th>Step</th>\n",
    "    <th>Method</th> \n",
    "    <th>Description</th>\n",
    "    <th>Number of Features</th>\n",
    "    <th>Accuracuy</th>\n",
    "    <th>Pos Recall</th>\n",
    "    <th>Pos F1 score</th>\n",
    "    <th>ROC score</th>\n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>Step 0</td>\n",
    "    <td>Benchmark</td> \n",
    "    <td>At this step I used five of supervised algorithoms to find out the best one that gives highest model performance. I have found Support vector machine is the one gives best model performances interms of accuracy, Recall, F-1 and ROC score.</td>\n",
    "     <td>61</td>\n",
    "    <td>77%</td> \n",
    "    <td>77%</td>\n",
    "    <td>76%</td>\n",
    "    <td>77.5%</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>Step 1</td>\n",
    "    <td>Grid search</td> \n",
    "    <td>After I select SVM as the model towards final solution, I used scikit-sklearn GridSearcgCV model to find best C and gamma parameters. After exhaustive search with many hours, the best C and gamma are 4.0 and 0.08</td>\n",
    "     <td>61</td>\n",
    "    <td>84.5%</td> \n",
    "    <td>81%</td>\n",
    "    <td>81%</td>\n",
    "    <td>84.5%</td> \n",
    "  </tr>\n",
    "  \n",
    "    <tr>\n",
    "    <td>Step 2.1 </td>\n",
    "    <td>Feature engineering</td> \n",
    "    <td>At this stage, I work with feature manipulations. I have tried adding some extra features like amplitude of the signal, mel coefficients etc. BUt the did not improve.</td>\n",
    "     <td>61-1285</td>\n",
    "    <td>84.50% - 75.00%</td> \n",
    "    <td>81.00% - 74.00%</td>\n",
    "    <td>81.00% - 78.00%</td>\n",
    "    <td>84.50% -69.00% </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning curve to check if more data is required to improve performance\n",
    "\n",
    "In this step of the project, I will check the learning curve of the support vector machine. A learning curve shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much we benefit from adding more training data and whether the estimator suffers more from a variance error or a bias error. If both the validation score and the training score converge to a value that is too low with increasing size of the training set, we will not benefit much from more training data. If the training score is much higher than the validation score for the maximum number of training samples, adding more training samples will most likely increase generalization. In the following plot of SVM estimator, we see that the model could benefit from more training examples. We have to add training data to get improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "# import visuals as vs\n",
    "# vz = vs.vizualization(df)\n",
    "# vz.check_model_learning(X_train, Y_train, svm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging of SVM\n",
    "\n",
    "In this bagging classification ithe above SVM model is the meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator, by introducing randomization into its construction procedure and then making an ensemble out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=SVC(C=100, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=6, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=0.4, n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging_svm = BaggingClassifier(svm_model, max_samples=0.4, n_estimators=100, n_jobs=-1)\n",
    "bagging_svm.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The accuracy of the model is 0.7919148936170213\n",
      "\n",
      "2. Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.80      0.81      2629\n",
      "        1.0       0.76      0.78      0.77      2071\n",
      "\n",
      "avg / total       0.79      0.79      0.79      4700\n",
      " \n",
      "\n",
      "3. Confusion matrix \n",
      " [[2106  455]\n",
      " [ 523 1616]] \n",
      "\n",
      "4. Roc_Auc score \n",
      " 0.7889141232560403\n"
     ]
    }
   ],
   "source": [
    "Y_pred = bagging_svm.predict(X_test)\n",
    "\n",
    "print('1. The accuracy of the model is {}\\n'.format(accuracy_score(Y_test, Y_pred)))\n",
    "print('2. Classification report \\n {} \\n'.format(classification_report(Y_test, Y_pred)))\n",
    "print('3. Confusion matrix \\n {} \\n'.format(confusion_matrix(Y_pred, Y_test)))\n",
    "print('4. Roc_Auc score \\n {}'.format(roc_auc_score(Y_pred, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
