{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import obspy\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import visuals as vs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "random_state = 6\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_seismogram(filename):\n",
    "    st = obspy.read(filename)\n",
    "    return st\n",
    "\n",
    "def extract_features(seismogram, signal_label):\n",
    "    data = seismogram[0].data\n",
    "    sample_rate = seismogram[0].stats.sampling_rate\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S = stft, sr = sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(data, sr = sample_rate).T,axis=0)\n",
    "    moment = sp.stats.moment(data)\n",
    "    variation = sp.stats.variation(data)\n",
    "    skew = sp.stats.skew(data)\n",
    "    var = np.var(data)\n",
    "    autocr = np.correlate(data, data)\n",
    "    kurto = sp.stats.kurtosis(data)\n",
    "    return np.hstack([mfccs,chroma,mel,moment,variation, skew, var, autocr, kurto, signal_label])\n",
    "\n",
    "def parse_and_stack_seismograms(parent_dir, sub_dirs):\n",
    "    \n",
    "    features = np.empty((0,187))\n",
    "    if parent_dir == 'seismograms/explosions/':\n",
    "        signal_label = 1\n",
    "    elif parent_dir == 'seismograms/earthquakes/':\n",
    "        signal_label = 0\n",
    "        \n",
    "    for indx, sub_dir in enumerate(sub_dirs):\n",
    "        for filename in glob.glob(os.path.join(parent_dir, sub_dir, '*.SAC')):\n",
    "            seismogram = read_seismogram(filename)\n",
    "            single_feature= extract_features(seismogram, signal_label)\n",
    "            features = np.vstack([features, single_feature])\n",
    "        \n",
    "    dataFrame = pd.DataFrame(features)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/librosa/core/pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    }
   ],
   "source": [
    "parent_dir = 'seismograms/explosions/'\n",
    "sub_dirs = ['1998-05-11-mb52-india','1998-05-28-mb48-pakistan', '1998-05-30-mb46-pakistan', '2013-02-12-mb51-north-korea', '2016-01-06-mb51-north-korea', '2017-09-03-mb63-north-korea']\n",
    "df_explosions  = parse_and_stack_seismograms(parent_dir,sub_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/librosa/core/pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n",
      "/usr/local/lib/python3.6/site-packages/obspy/core/trace.py:187: UserWarning: Calibration factor set to 0.0!\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "parent_dir = 'seismograms/earthquakes/'\n",
    "sub_dirs = ['2004-12-26-mw90-sumatra', '2010-03-12-mw55-myanmar-india-border-region', '2017-08-15-mb49-southeast-of-ryukyu-islands', '2017-09-08-mww81-near-coast-of-chiapas-mexico']\n",
    "df_earthquakes  = parse_and_stack_seismograms(parent_dir,sub_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1606, 187)\n",
      "(1606, 186)\n"
     ]
    }
   ],
   "source": [
    "frames = [df_explosions, df_earthquakes]\n",
    "df = pd.concat(frames)\n",
    "X = df.iloc[:,:186]\n",
    "Y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=random_state)\n",
    "mms = StandardScaler()\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_test = mms.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "rfc = RandomForestClassifier(criterion='entropy', random_state = random_state, class_weight='balanced')\n",
    "params = {\n",
    "    'n_estimators': [10, 20, 50, 100],\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [10, 20, 40, 50]\n",
    "}\n",
    "\n",
    "grid_clf = GridSearchCV(estimator = rfc, param_grid = params, scoring = 'accuracy', cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=6, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='entropy', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=6, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [10, 20, 50, 100], 'max_depth': [1, 2, 3, 4, 5], 'min_samples_split': [10, 20, 40, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have to find out best optimized parameters\n",
    "grid_clf.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " # Best estimator ---------\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=5, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=6, verbose=0, warm_start=False)\n",
      "\n",
      " # Best parameters ---------\n",
      "{'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "\n",
      " # Best score ---------\n",
      "0.8211743772241993\n"
     ]
    }
   ],
   "source": [
    "# get the best model\n",
    "print('\\n # Best estimator ---------\\n{}'.format(grid_clf.best_estimator_))\n",
    "\n",
    "# Get the best parameters\n",
    "print('\\n # Best parameters ---------\\n{}'.format(grid_clf.best_params_))\n",
    "\n",
    "# best score\n",
    "print('\\n # Best score ---------\\n{}'.format(grid_clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = grid_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 0.6887966804979253\n",
      "# Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.99      0.81       322\n",
      "        1.0       0.78      0.09      0.16       160\n",
      "\n",
      "avg / total       0.72      0.69      0.59       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print('The accuracy of the model is {}'.format(accuracy_score(Y_test, Y_pred)))\n",
    "print('# Classification report \\n {}'.format(classification_report(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[318, 146],\n",
       "       [  4,  14]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X, Y)\n",
    "Y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 0.6680497925311203\n",
      "# Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      1.00      0.80       322\n",
      "        1.0       0.00      0.00      0.00       160\n",
      "\n",
      "avg / total       0.45      0.67      0.54       482\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy of the model is {}'.format(accuracy_score(Y_test, Y_pred)))\n",
    "print('# Classification report \\n {}'.format(classification_report(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
