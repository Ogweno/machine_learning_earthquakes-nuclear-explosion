{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import obspy\n",
    "import glob\n",
    "import os, sys\n",
    "import librosa\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal as signal\n",
    "import pandas as pd\n",
    "import visuals as vs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "random_state = 6\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_seismogram(filename):\n",
    "    st = obspy.read(filename)\n",
    "    return st\n",
    "\n",
    "def extract_features(seismogram, signal_label):\n",
    "    data = seismogram[0].data\n",
    "    sample_rate = seismogram[0].stats.sampling_rate\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S = stft, sr = sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(data, sr = sample_rate).T,axis=0)\n",
    "    f, Pwelch_spec = signal.welch(data, sample_rate, scaling='spectrum')\n",
    "#     tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(data),sr=sample_rate).T,axis=0)\n",
    "    moment = sp.stats.moment(data)\n",
    "    variation = sp.stats.variation(data)\n",
    "    skew = sp.stats.skew(data)\n",
    "    var = np.var(data)\n",
    "    autocr = np.correlate(data, data)\n",
    "    kurto = sp.stats.kurtosis(data)\n",
    "    return np.hstack([mfccs,chroma,mel,Pwelch_spec, moment,variation, skew, var, autocr, kurto, signal_label])\n",
    "\n",
    "def parse_and_stack_seismograms(parent_dir, sub_dirs):\n",
    "    \n",
    "    features = np.empty((0,316))\n",
    "    if parent_dir == 'seismograms/explosions/':\n",
    "        signal_label = 1\n",
    "    elif parent_dir == 'seismograms/earthquakes/':\n",
    "        signal_label = 0\n",
    "        \n",
    "    for indx, sub_dir in enumerate(sub_dirs):\n",
    "        for filename in glob.glob(os.path.join(parent_dir, sub_dir, '*.SAC')):\n",
    "            seismogram = read_seismogram(filename)\n",
    "            single_feature= extract_features(seismogram, signal_label)\n",
    "            features = np.vstack([features, single_feature])\n",
    "        \n",
    "    dataFrame = pd.DataFrame(features)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/librosa/core/pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    }
   ],
   "source": [
    "parent_dir = 'seismograms/explosions/'\n",
    "sub_dirs = ['1998-05-11-mb52-india','1998-05-28-mb48-pakistan', '1998-05-30-mb46-pakistan', '2013-02-12-mb51-north-korea', '2016-01-06-mb51-north-korea', '2017-09-03-mb63-north-korea']\n",
    "df_explosions  = parse_and_stack_seismograms(parent_dir,sub_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/librosa/core/pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n",
      "/usr/local/lib/python3.6/site-packages/obspy/core/trace.py:187: UserWarning: Calibration factor set to 0.0!\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "parent_dir = 'seismograms/earthquakes/'\n",
    "sub_dirs = ['2004-12-26-mw90-sumatra', '2010-03-12-mw55-myanmar-india-border-region', '2017-08-15-mb49-southeast-of-ryukyu-islands', '2017-09-08-mww81-near-coast-of-chiapas-mexico']\n",
    "df_earthquakes  = parse_and_stack_seismograms(parent_dir,sub_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_explosions, df_earthquakes]\n",
    "df = pd.concat(frames)\n",
    "X = df.iloc[:,:186]\n",
    "Y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('seismogram_data_pwelch_spec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "rfc = RandomForestClassifier(criterion='entropy', random_state = random_state, class_weight='balanced')\n",
    "params = {\n",
    "    'n_estimators': [10, 20, 50, 100],\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [10, 20, 40, 50]\n",
    "}\n",
    "\n",
    "grid_clf = GridSearchCV(estimator = rfc, param_grid = params, scoring = 'accuracy', cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=6, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='entropy', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=6, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [10, 20, 50, 100], 'max_depth': [1, 2, 3, 4, 5], 'min_samples_split': [10, 20, 40, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have to find out best optimized parameters\n",
    "grid_clf.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "filename = 'seismogram_data.csv'\n",
    "# filename = 'seismogram_data_pwelch_spec.csv'\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "n_feature = np.shape(df)[1] - 2\n",
    "\n",
    "X = df.iloc[:,:n_feature]\n",
    "Y = df.iloc[:,-1]\n",
    "\n",
    "X, Y = shuffle(X, Y, random_state = random_state)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state=random_state)\n",
    "mms = StandardScaler()\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_test = mms.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 0.7935323383084577\n",
      "# Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.79      0.84       276\n",
      "        1.0       0.64      0.79      0.71       126\n",
      "\n",
      "avg / total       0.81      0.79      0.80       402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "class_weight = {0:1, 1:2}\n",
    "\n",
    "model = RandomForestClassifier(bootstrap=True, class_weight=class_weight,\n",
    "            criterion='entropy', max_depth=4, max_features='auto',\n",
    "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
    "            min_samples_leaf=1, min_samples_split=10,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "            oob_score=False, random_state=random_state, verbose=0, warm_start=False)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "print('The accuracy of the model is {}'.format(accuracy_score(Y_test, Y_pred)))\n",
    "print('# Classification report \\n {}'.format(classification_report(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[219,  26],\n",
       "       [ 57, 100]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
